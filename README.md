# analisis-accidentes-transito
"Proyecto en PySpark para analizar accidentes de tr치nsito desde HDFS"
# An치lisis de Accidentes de Tr치nsito con PySpark

Este proyecto realiza un an치lisis de datos de accidentes de tr치nsito utilizando PySpark. Los datos provienen del portal de datos abiertos de Colombia y se procesan desde un archivo CSV almacenado en HDFS.

## 游늭 Estructura del Proyecto
- `accidentes.py`: Script principal que lee el archivo CSV desde HDFS, realiza an치lisis por a침o, d칤a de la semana y gravedad, y muestra estad칤sticas.
- `wacd-xkg8.csv`: Archivo de datos de accidentes (subido a HDFS).
- `README.md`: Este archivo con la descripci칩n del proyecto.
- `requirements.txt`: Lista de dependencias necesarias para ejecutar el proyecto.

## 游늵 An치lisis Realizado
- Conteo de accidentes por a침o (`a_o`)
- Conteo de accidentes por d칤a de la semana (`dia`)
- Conteo de accidentes por nivel de gravedad (`gravedad`)
- Estad칤sticas descriptivas del conjunto de datos

## 游 Instrucciones de Ejecuci칩n

### 1. Subir el archivo CSV a HDFS

Crea un entorno virtual e instala dependencias:
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

### 2. Subir el archivo CSV a HDFS
hdfs dfs -put /ruta/local/wacd-xkg8.csv /Tarea3

### 3. Ejecutar el script
python3 accidentes.py

### Requisitos

Python 3
PySpark 3.5.6
Hadoop configurado con HDFS

### Fuente de datos
Datos Abiertos Colombia

### Ejemplo de salida
Accidentes por a침o:
+----+-----+
|a_o |count|
+----+-----+
|2017|  500|
|2018|  300|
|2019|  200|
|2020|   50|
+----+-----+

Accidentes por gravedad:
+-----------+-----+
|gravedad   |count|
+-----------+-----+
|SOLO DA칌OS |  700|
|CON HERIDOS|  300|
|CON MUERTOS|   50|
+-----------+-----+

